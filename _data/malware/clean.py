#!/usr/bin/env python

"""
    clean.py
"""

import numpy as np
from pygtrie import CharTrie
from collections import Counter
from pyspark import SparkContext

def parse_line(x):
    try:
        filename, edge = x.split('\t')
        src, dsts = edge.split(' ==> ')
        if dsts[0] == '[':
            dsts = [d.strip() for d in eval(dsts)]
        else:
            dsts = [dsts]
        
        return (filename, (src, dsts))
    except:
        return None


def find_long(x, lookup):
    for l in lookup:
        if l == x[1:len(l)+1]:
            return l
    
    # If no match
    pct_short = np.mean([len(xx) < 3 for xx in x.split('.')])
    if pct_short > 0.5:
        return '_obfuscated'
    else:
        return '_selfdefined'

def compress_ids(x, lookup):
    src  = find_long(x[0], lookup)
    dsts = [find_long(xx, lookup) for xx in x[1]]
    for dst, count in Counter(dsts).items():
        yield src, dst, count


def parse_class(x):
    return x.split(':')[0][1:].split('$')[0]

def compress_classes(x):
    src = parse_class(x[0])
    dsts = map(parse_class, x[1])
    for dst, count in Counter(dsts).items():
        yield src, dst, count

# --

# sc = SparkContext(appName="parse_malware")

inpath = '/user/bjohnson/data/hive/malware/mamadroid'

lines = sc.textFile(inpath, use_unicode=False)\
    .map(parse_line)\
    .filter(lambda x: x is not None)


# --
# Class level

classes = lines.flatMapValues(compress_classes)\
    .map(lambda x: ((x[0], x[1][0], x[1][1]), x[1][2]))\
    .reduceByKey(lambda a,b: a + b)\
    .map(lambda x: (x[0][0], x[0][1], x[0][2], x[1]))\
    .map(lambda x: '\t'.join(map(str, x)))\
    .saveAsTextFile(
        '/user/bjohnson/data/hive/malware/mamadroid-compressed/class-x001',
        compressionCodecClass="org.apache.hadoop.io.compress.GzipCodec"
    )


sc.textFile('/user/bjohnson/data/hive/malware/mamadroid-compressed/class-x001')\
    .saveAsTextFile(
        '/user/bjohnson/data/hive/malware/mamadroid-compressed/class',
        compressionCodecClass="org.apache.hadoop.io.compress.GzipCodec"
    )


# --
# Package level

package_lookup = sc.textFile('/user/bjohnson/data/hive/malware/packages-list.txt').collect()
package_lookup = sorted(package_lookup, key=lambda x: -len(x))

_ = lines.flatMapValues(lambda x: compress_ids(x, package_lookup))\
    .map(lambda x: ((x[0], x[1][0], x[1][1]), x[1][2]))\
    .reduceByKey(lambda a,b: a + b)\
    .map(lambda x: (x[0][0], x[0][1], x[0][2], x[1]))\
    .map(lambda x: '\t'.join(map(str, x)))\
    .saveAsTextFile(
        '/user/bjohnson/data/hive/malware/mamadroid-compressed/package',
        compressionCodecClass="org.apache.hadoop.io.compress.GzipCodec"
    )


# --
# Family level

family_lookup = sc.textFile('/user/bjohnson/data/hive/malware/families-list.txt').collect()
family_lookup = sorted(family_lookup, key=lambda x: -len(x))

_ = lines.flatMapValues(lambda x: compress_ids(x, family_lookup))\
    .map(lambda x: ((x[0], x[1][0], x[1][1]), x[1][2]))\
    .reduceByKey(lambda a,b: a + b)\
    .map(lambda x: (x[0][0], x[0][1], x[0][2], x[1]))\
    .map(lambda x: '\t'.join(map(str, x)))\
    .saveAsTextFile(
        '/user/bjohnson/data/hive/malware/mamadroid-compressed/family',
        compressionCodecClass="org.apache.hadoop.io.compress.GzipCodec"
    )

